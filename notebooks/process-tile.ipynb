{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d792711-e449-4736-9429-55bcc584c6c8",
   "metadata": {},
   "source": [
    "# Processing Scene Classification Layer from sentinel 2 data\n",
    "- 0 No data\n",
    "- 1 Saturated or defective\n",
    "- 2 Dark area pixels\n",
    "- 3 Cloud shadows\n",
    "- 4 Vegetation\n",
    "- 5 Bare soils\n",
    "- 6 Water\n",
    "- 7 Unclassified\n",
    "- 8 Cloud medium probability\n",
    "- 9 Cloud high probability\n",
    "- 10 Thin cirrus\n",
    "- 11 Snow or ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8585d2d3-b2fb-49bf-a1c1-11799e40e23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.191  Python-3.10.6 torch-2.0.1+cpu CPU (Intel Core(TM) i7-1065G7 1.30GHz)\n",
      "Setup complete  (8 CPUs, 15.8 GB RAM, 359.0/400.7 GB disk)\n",
      "\n",
      "0: 640x640 (no detections), 1: 640x640 (no detections), 2: 640x640 (no detections), 3: 640x640 8 boats, 4: 640x640 2 boats, 5: 640x640 1 boat, 6: 640x640 (no detections), 7: 640x640 6 boats, 6559.3ms\n",
      "Speed: 3.6ms preprocess, 819.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "test_imgs = Path('.').glob('cropped-*.tif')\n",
    "test_imgs = [str(x) for x in test_imgs]\n",
    "len(test_imgs)\n",
    "# Other models to test: https://github.com/swricci/small-boat-detector\n",
    "# From https://github.com/robmarkcole/kaggle-ships-in-Google-Earth-with-YOLOv8/blob/main/models/yolov8m_best.pt\n",
    "model = YOLO(f'../models/yolov8m_best.pt')\n",
    "results = model.predict(source=test_imgs, conf=0.2, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a6955d6-8f2e-4ddd-a3e5-e9a9f4909cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "-----------\n",
      "-----------\n",
      "-----------\n",
      "cropped-4071275113.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.5807])\n",
      "data: tensor([[181.4869, 153.4355, 189.7488, 161.7322,   0.5807,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (310, 310)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[185.6178, 157.5839,   8.2619,   8.2966]])\n",
      "xywhn: tensor([[0.5988, 0.5083, 0.0267, 0.0268]])\n",
      "xyxy: tensor([[181.4869, 153.4355, 189.7488, 161.7322]])\n",
      "xyxyn: tensor([[0.5854, 0.4950, 0.6121, 0.5217]])\n",
      "cropped-4071275113.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.5007])\n",
      "data: tensor([[ 55.6107, 178.0184,  58.4260, 181.0248,   0.5007,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (310, 310)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[ 57.0183, 179.5216,   2.8153,   3.0064]])\n",
      "xywhn: tensor([[0.1839, 0.5791, 0.0091, 0.0097]])\n",
      "xyxy: tensor([[ 55.6107, 178.0184,  58.4260, 181.0248]])\n",
      "xyxyn: tensor([[0.1794, 0.5743, 0.1885, 0.5840]])\n",
      "cropped-4071275113.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.4954])\n",
      "data: tensor([[116.8755, 197.3284, 119.5705, 201.3596,   0.4954,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (310, 310)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[118.2230, 199.3440,   2.6949,   4.0312]])\n",
      "xywhn: tensor([[0.3814, 0.6430, 0.0087, 0.0130]])\n",
      "xyxy: tensor([[116.8755, 197.3284, 119.5705, 201.3596]])\n",
      "xyxyn: tensor([[0.3770, 0.6365, 0.3857, 0.6495]])\n",
      "cropped-4071275113.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.4885])\n",
      "data: tensor([[ 22.5084, 266.0286,  28.7113, 273.0778,   0.4885,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (310, 310)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[ 25.6099, 269.5532,   6.2028,   7.0492]])\n",
      "xywhn: tensor([[0.0826, 0.8695, 0.0200, 0.0227]])\n",
      "xyxy: tensor([[ 22.5084, 266.0286,  28.7113, 273.0778]])\n",
      "xyxyn: tensor([[0.0726, 0.8582, 0.0926, 0.8809]])\n",
      "cropped-4071275113.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.4852])\n",
      "data: tensor([[160.1912, 278.4611, 163.3791, 282.1530,   0.4852,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (310, 310)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[161.7851, 280.3070,   3.1879,   3.6919]])\n",
      "xywhn: tensor([[0.5219, 0.9042, 0.0103, 0.0119]])\n",
      "xyxy: tensor([[160.1912, 278.4611, 163.3791, 282.1530]])\n",
      "xyxyn: tensor([[0.5167, 0.8983, 0.5270, 0.9102]])\n",
      "cropped-4071275113.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3324])\n",
      "data: tensor([[53.8763, 24.7718, 56.6183, 29.2272,  0.3324,  0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (310, 310)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[55.2473, 26.9995,  2.7420,  4.4554]])\n",
      "xywhn: tensor([[0.1782, 0.0871, 0.0088, 0.0144]])\n",
      "xyxy: tensor([[53.8763, 24.7718, 56.6183, 29.2272]])\n",
      "xyxyn: tensor([[0.1738, 0.0799, 0.1826, 0.0943]])\n",
      "cropped-4071275113.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3209])\n",
      "data: tensor([[93.5880, 54.0213, 96.3012, 57.2730,  0.3209,  0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (310, 310)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[94.9446, 55.6472,  2.7132,  3.2518]])\n",
      "xywhn: tensor([[0.3063, 0.1795, 0.0088, 0.0105]])\n",
      "xyxy: tensor([[93.5880, 54.0213, 96.3012, 57.2730]])\n",
      "xyxyn: tensor([[0.3019, 0.1743, 0.3106, 0.1848]])\n",
      "cropped-4071275113.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2142])\n",
      "data: tensor([[8.9353e+00, 2.9267e+02, 1.1816e+01, 2.9741e+02, 2.1420e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (310, 310)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[ 10.3757, 295.0416,   2.8808,   4.7374]])\n",
      "xywhn: tensor([[0.0335, 0.9517, 0.0093, 0.0153]])\n",
      "xyxy: tensor([[  8.9353, 292.6729,  11.8161, 297.4103]])\n",
      "xyxyn: tensor([[0.0288, 0.9441, 0.0381, 0.9594]])\n",
      "-----------\n",
      "cropped-4071275213.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.7568])\n",
      "data: tensor([[292.2223, 181.4994, 297.8782, 194.6690,   0.7568,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (309, 310)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[295.0503, 188.0842,   5.6559,  13.1695]])\n",
      "xywhn: tensor([[0.9518, 0.6087, 0.0182, 0.0426]])\n",
      "xyxy: tensor([[292.2223, 181.4994, 297.8782, 194.6690]])\n",
      "xyxyn: tensor([[0.9427, 0.5874, 0.9609, 0.6300]])\n",
      "cropped-4071275213.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.6077])\n",
      "data: tensor([[299.0106, 243.4484, 309.7002, 259.1036,   0.6077,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (309, 310)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[304.3553, 251.2760,  10.6896,  15.6551]])\n",
      "xywhn: tensor([[0.9818, 0.8132, 0.0345, 0.0507]])\n",
      "xyxy: tensor([[299.0106, 243.4484, 309.7002, 259.1036]])\n",
      "xyxyn: tensor([[0.9646, 0.7879, 0.9990, 0.8385]])\n",
      "-----------\n",
      "cropped-4072275013.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3138])\n",
      "data: tensor([[187.2676, 242.3046, 191.4653, 244.7414,   0.3138,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (309, 309)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[189.3665, 243.5230,   4.1978,   2.4368]])\n",
      "xywhn: tensor([[0.6128, 0.7881, 0.0136, 0.0079]])\n",
      "xyxy: tensor([[187.2676, 242.3046, 191.4653, 244.7414]])\n",
      "xyxyn: tensor([[0.6060, 0.7842, 0.6196, 0.7920]])\n",
      "-----------\n",
      "-----------\n",
      "cropped-4072275213.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.8550])\n",
      "data: tensor([[214.5726, 276.5720, 224.8279, 288.2362,   0.8550,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (309, 309)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[219.7002, 282.4041,  10.2553,  11.6643]])\n",
      "xywhn: tensor([[0.7110, 0.9139, 0.0332, 0.0377]])\n",
      "xyxy: tensor([[214.5726, 276.5720, 224.8279, 288.2362]])\n",
      "xyxyn: tensor([[0.6944, 0.8951, 0.7276, 0.9328]])\n",
      "cropped-4072275213.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.8532])\n",
      "data: tensor([[ 80.8654, 292.0860,  91.0297, 303.3983,   0.8532,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (309, 309)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[ 85.9476, 297.7421,  10.1643,  11.3123]])\n",
      "xywhn: tensor([[0.2781, 0.9636, 0.0329, 0.0366]])\n",
      "xyxy: tensor([[ 80.8654, 292.0860,  91.0297, 303.3983]])\n",
      "xyxyn: tensor([[0.2617, 0.9453, 0.2946, 0.9819]])\n",
      "cropped-4072275213.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.7482])\n",
      "data: tensor([[157.2921, 215.2416, 163.3602, 226.6838,   0.7482,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (309, 309)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[160.3261, 220.9627,   6.0681,  11.4421]])\n",
      "xywhn: tensor([[0.5189, 0.7151, 0.0196, 0.0370]])\n",
      "xyxy: tensor([[157.2921, 215.2416, 163.3602, 226.6838]])\n",
      "xyxyn: tensor([[0.5090, 0.6966, 0.5287, 0.7336]])\n",
      "cropped-4072275213.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.7117])\n",
      "data: tensor([[ 59.2829, 228.6020,  64.1882, 240.3212,   0.7117,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (309, 309)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[ 61.7356, 234.4616,   4.9053,  11.7192]])\n",
      "xywhn: tensor([[0.1998, 0.7588, 0.0159, 0.0379]])\n",
      "xyxy: tensor([[ 59.2829, 228.6020,  64.1882, 240.3212]])\n",
      "xyxyn: tensor([[0.1919, 0.7398, 0.2077, 0.7777]])\n",
      "cropped-4072275213.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.5259])\n",
      "data: tensor([[133.3671, 146.5921, 138.2948, 150.1262,   0.5259,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (309, 309)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[135.8309, 148.3591,   4.9277,   3.5341]])\n",
      "xywhn: tensor([[0.4396, 0.4801, 0.0159, 0.0114]])\n",
      "xyxy: tensor([[133.3671, 146.5921, 138.2948, 150.1262]])\n",
      "xyxyn: tensor([[0.4316, 0.4744, 0.4476, 0.4858]])\n",
      "cropped-4072275213.tif\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.2124])\n",
      "data: tensor([[ 20.5614, 163.9503,  24.0563, 167.7911,   0.2124,   0.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (309, 309)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[ 22.3089, 165.8707,   3.4950,   3.8408]])\n",
      "xywhn: tensor([[0.0722, 0.5368, 0.0113, 0.0124]])\n",
      "xyxy: tensor([[ 20.5614, 163.9503,  24.0563, 167.7911]])\n",
      "xyxyn: tensor([[0.0665, 0.5306, 0.0779, 0.5430]])\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(\"-----------\")\n",
    "    for box in result.boxes:\n",
    "        print(result.path)\n",
    "        print(box)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
